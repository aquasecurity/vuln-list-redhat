{
  "affected_release": null,
  "package_state": [
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/bootc-aws-nvidia-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/bootc-azure-amd-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/bootc-azure-nvidia-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/bootc-gcp-nvidia-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/bootc-ibm-nvidia-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/bootc-intel-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/bootc-nvidia-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/instructlab-amd-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/instructlab-intel-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    },
    {
      "product_name": "Red Hat Enterprise Linux AI (RHEL AI)",
      "fix_state": "Affected",
      "package_name": "rhelai1/instructlab-nvidia-rhel9",
      "cpe": "cpe:/a:redhat:enterprise_linux_ai:1"
    }
  ],
  "threat_severity": "Important",
  "public_date": "2025-01-27T17:38:20Z",
  "bugzilla": {
    "description": "vllm: vLLM allows a malicious model RCE by torch.load in hf_model_weights_iterator",
    "id": "2342304",
    "url": "https://bugzilla.redhat.com/show_bug.cgi?id=2342304"
  },
  "cvss": {
    "cvss_base_score": "",
    "cvss_scoring_vector": "",
    "status": ""
  },
  "cvss3": {
    "cvss3_base_score": "7.5",
    "cvss3_scoring_vector": "CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H",
    "status": "draft"
  },
  "iava": "",
  "cwe": "CWE-502",
  "statement": "",
  "acknowledgement": "",
  "name": "CVE-2025-24357",
  "document_distribution": "",
  "details": [
    "vLLM is a library for LLM inference and serving. vllm/model_executor/weight_utils.py implements hf_model_weights_iterator to load the model checkpoint, which is downloaded from huggingface. It uses the torch.load function and the weights_only parameter defaults to False. When torch.load loads malicious pickle data, it will execute arbitrary code during unpickling. This vulnerability is fixed in v0.7.0.",
    "A flaw was found in the vLLM package, a library for LLM inference and serving. The vllm/model_executor/weight_utils.py implements hf_model_weights_iterator to load the model checkpoint downloaded from huggingface. It uses the torch.load function, and the weights_only parameter defaults to False. When torch.load loads malicious pickle data, it will execute arbitrary code during unpickling. This vulnerability can be exploited to execute arbitrary codes and OS commands in the victim machine that fetches the pre-trained repo remotely."
  ],
  "references": [
    "https://www.cve.org/CVERecord?id=CVE-2025-24357\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-24357\nhttps://github.com/vllm-project/vllm/commit/d3d6bb13fb62da3234addf6574922a4ec0513d04\nhttps://github.com/vllm-project/vllm/pull/12366\nhttps://github.com/vllm-project/vllm/security/advisories/GHSA-rh4j-5rhw-hr54\nhttps://pytorch.org/docs/stable/generated/torch.load.html"
  ]
}